The data in this study collected video data for cattle facial recognition from two Chinese farms (125.622115N, 43.956535E). Simmental beef cattle were selected as the research object, and a total of 334 video recordings of 167 cattle were completed. Each cattle stores two videos, one shot from the front view of the mobile phone, and the other from the mobile phone's upward view of the cattle.

We manually annotated the data set and completed the annotation of the data target box and key points. The data annotation box annotation method WiderFace annotation format (x, y, w, h) and the key point annotation format is the center of the cow's left eye (lx1, ly1), right eye center (lx2, ly2), nose center (l3x, l3y), left mouth corner (l4x, l4y) and right mouth corner (l5x, l5y), and save them in txt.

We manually analyzed the experimental data and found that for the cattle1 data set, front face: side face: extreme side face is close to 2.9: 5.45: 1, which shows that in real life, when we collect cattle face images, we tend to collect side faces, which means Under real farm conditions, it is difficult to obtain a perfect frontal face image. At the same time, in order to obtain a suitable recognition data set like normal face images, we conducted a second collection. Most of the cattle2 collected this time were frontal face data. , the front-to-side ratio is close to 3.2:1. A total of 35703 images of data were collected.

The dataset and code will be made public after the paper is published, so stay tuned

